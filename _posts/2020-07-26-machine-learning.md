---
layout: post
keywords: Machine Learning
description: Machine Learning 
title: "机器学习基础"
categories: [ML]
tags: [ai,ml]
---
{% include codepiano/setup %}

## AI算法

## 基础科普
* 深度学习、神经网络、机器学习、人工智能的关系
    * 机器学习是AI的一个分支
    * 深度学习是机器学习的一个重要分支
    * 深度学习的概念源于人工神经网络的研究，但是并不完全等于传统神经网络。（是传统神经网络的升级，约等于神经网络）
    * 神经网络是一个网络结构，深度学习就是对这个网络结构进行调整()
```
   传统机器学习： 数据预处理  -->  特征提取  --> 选择分类器
   深度学习   ： 数据预处理  -->  设计模型  --> 训练
```

* 4种典型的深度学习算法
    * CNN 卷积神经网络,最擅长图片处理
        * CNN 的基本原理：
            卷积层 – 主要作用是保留图片的特征(提取图像中的局部特征)
            池化层 – 主要作用是把数据降维，可以有效的避免过拟合（用来大幅降低参数量级(降维)）
            全连接层 – 根据不同任务输出我们想要的结果
        * 运用场景
            图像分类、检索：图像搜索
            目标定位检测：自动驾驶、安防、医疗
            目标分割：美图、视频后期加工、图像生成
            人脸识别：安防、金融、生活
            骨骼识别：安防、电影、图像视频生成、游戏
    * RNN 循环神经网络
        * 特点
            卷积神经网络 – CNN 和普通的算法大部分都是输入和输出的一一对应，也就是一个输入得到一个输出。不同的输入之间是没有联系的。
            RNN 跟传统神经网络最大的区别在于每次都会将前一次的输出结果，带到下一次的隐藏层中，一起训练。
            RNN 有短期记忆问题，无法处理很长的输入序列
            训练 RNN 需要投入极大的成本
            由于 RNN 的短期记忆问题，后来又出现了基于 RNN 的优化算法
        * 优化 LSTM 和 GRU
            RNN 是一种死板的逻辑，越晚的输入影响越大，越早的输入影响越小，且无法改变这个逻辑。
            LSTM 做的最大的改变就是打破了这个死板的逻辑，而改用了一套灵活了逻辑——只保留重要的信息。
            GRU 主要是在 LSTM 的模型上做了一些简化和调整，在训练数据集比较大的情况下可以节省很多时间
        * 使用场景
            文本生成：填空题，给出前后文，然后预测空格中的词是什么。
            机器翻译：翻译工作也是典型的序列问题，词的顺序直接影响了翻译的结果。
            语音识别：根据输入音频判断对应的文字是什么。
            生成图像描述：类似看图说话，给一张图，能够描述出图片中的内容。这个往往是 RNN 和 CNN 的结合。
            视频标记：他将视频分解为图片，然后用图像描述来描述图片内容。
    * GANs 生成对抗网络
    * RL 深度强化学习


## 机器学习

## 深度学习

## 自然语言处理

## 计算机视觉

## 语音交互